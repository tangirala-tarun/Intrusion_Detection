{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fa66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas_profiling as pp\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1584b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\Datasets\\Train_test_iot\\Train_Test_IoT_Weather.csv\")\n",
    "\n",
    "# profile = pp.ProfileReport(df)\n",
    "# profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b34871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ts','date','time','label'],axis=1,inplace=True)\n",
    "\n",
    "label_encoder=preprocessing.LabelEncoder()\n",
    "df['type']=label_encoder.fit_transform(df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3330a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.loc[:,['temperature','pressure','humidity']] # input\n",
    "y=df.loc[:,['type']] # target\n",
    "\n",
    "# splitting thee dataset into training and testing sets\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a4e221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6125548430644617\n",
      "Recall:  0.6125548430644617\n",
      "F1score:  0.5302400936165133\n"
     ]
    }
   ],
   "source": [
    "gnb=GaussianNB()\n",
    "model=gnb.fit(x_train,y_train.values.ravel())\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe69fe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m mnb\u001b[38;5;241m=\u001b[39mMultinomialNB()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mmnb\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m,accuracy_score(y_test,y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:726\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:851\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 851\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1372\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1369\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_train,y_train.values.ravel())\n",
    "y_pred=mnb.predict(x_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average=\"weighted\"))\n",
    "print(\"F1 score: \",f1_score(y_test,y_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce36f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8064461694228822\n",
      "Recall:  0.8064461694228822\n",
      "F1score:  0.783600913344279\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rfc.fit(x_train,y_train.values.ravel())\n",
    "y_pred=rfc.predict(x_test)\n",
    "# print(y_test)\n",
    "# print(y_pred)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fb600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9814377320283496\n",
      "Recall:  0.9814377320283496\n",
      "F1score:  0.9813322317116517\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier=xgb.XGBClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "xgb_classifier.fit(x_train,y_train.values.ravel())\n",
    "y_pred=xgb_classifier.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413edf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7685341433232085\n",
      "Recall:  0.7685341433232085\n",
      "F1score:  0.7505334673654646\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=500, random_state=42)\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d7d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.31797727528405895\n",
      "Recall:  0.31797727528405895\n",
      "F1score:  0.34844296785798023\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=100, learning_rate=1, random_state=42)\n",
    "# Train Adaboost Classifer\n",
    "model1 = abc.fit(x_train, y_train.values.ravel())\n",
    "#Predict the response for test dataset\n",
    "y_pred = model1.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(probability=True, kernel='linear')\n",
    "abcd =AdaBoostClassifier(n_estimators=100, base_estimator=svc,learning_rate=1, random_state=42)\n",
    "\n",
    "# train adaboost classifer\n",
    "model2 = abcd.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "# predict the response for test dataset\n",
    "y_pred = model2.predict(x_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "#print(\"Precision: \",precision_score(y_test,y_pred,average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test,y_pred,average='weighted'))\n",
    "print(\"F1score: \",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52bd00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
